{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 算数操作\n",
    "## 加法一"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.3842,  0.5717,  2.1196,  1.3433,  0.3387],\n",
      "        [ 2.5572,  0.9532,  0.9249, -1.5904,  0.3159],\n",
      "        [ 1.5556,  0.0898, -1.0415, -0.0334, -0.4741]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x=torch.empty(3,5)\n",
    "y=torch.randn(3,5)\n",
    "print(x+y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加法二"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.3842,  0.5717,  2.1196,  1.3433,  0.3387],\n",
      "        [ 2.5572,  0.9532,  0.9249, -1.5904,  0.3159],\n",
      "        [ 1.5556,  0.0898, -1.0415, -0.0334, -0.4741]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.add(x,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加法三"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.3842,  0.5717,  2.1196,  1.3433,  0.3387],\n",
      "        [ 2.5572,  0.9532,  0.9249, -1.5904,  0.3159],\n",
      "        [ 1.5556,  0.0898, -1.0415, -0.0334, -0.4741]])\n"
     ]
    }
   ],
   "source": [
    "result=torch.empty(3,5)\n",
    "torch.add(x,y,out=result)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加法四 inplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.3842,  0.5717,  2.1196,  1.3433,  0.3387],\n",
      "        [ 2.5572,  0.9532,  0.9249, -1.5904,  0.3159],\n",
      "        [ 1.5556,  0.0898, -1.0415, -0.0334, -0.4741]])\n"
     ]
    }
   ],
   "source": [
    "y.add_(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 索引\n",
    "我们还可以使用类似NumPy的索引操作来访问```Tensor```的一部分，需要注意的是：**索引出来的结果与元数据共享内存，即修改一个，另一个会跟着修改。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9.2755e-39, 1.0837e-38, 8.4490e-39, 1.0561e-38, 8.4490e-39],\n",
      "        [9.6429e-39, 8.4490e-39, 9.6429e-39, 9.2755e-39, 1.0286e-38],\n",
      "        [9.0919e-39, 8.9082e-39, 9.2755e-39, 8.4490e-39, 1.0194e-38]])\n",
      "tensor([9.2755e-39, 9.6429e-39, 9.0919e-39])\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "y=x[:,0]\n",
    "y+=1\n",
    "print(y)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "除了常用的索引选择数据之外，PyTorch还提供了一些高级的选择函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "index_select(input, dim, index)\n",
    "masked_select(input, mask)\n",
    "non_zero(input) \n",
    "gather(input, dim, index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 改变形状\n",
    "用```view()```来改变```Tensor```的形状："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 5]) torch.Size([15]) torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "y = x.view(15)\n",
    "z = x.view(-1,3)\n",
    "print(x.size(),y.size(),z.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**注意```view()```返回的新Tensor与源Tensor共享内存（其实是同一个tensor），即更改其中一个，另一个也会跟着改变。\n",
    "顾名思义，view仅仅是改变了对这个张量的观察角度。***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所以如果我们想返回一个真正的新的副本（即不共享内存），PyTorch提供了一个```reshape()```函数可以改变形状，但是次函数不保证返回的是其拷贝，所以不推荐使用。推荐先用```clone```创造一个副本然后再使用```view```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1., -1., -1., -1., -1.],\n",
      "        [-1., -1., -1., -1., -1.],\n",
      "        [-1., -1., -1., -1., -1.]])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "x_cp=x.clone().view(15)\n",
    "x -=1\n",
    "print(x)\n",
    "print(x_cp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用```clone```还有一个好处是会被记录在计算图中，即梯度回传到副本时也会传到源```Tensor```中。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "另外一个常用的函数是```item()```，它可以讲一个标量```Tensor```转换成Python Number："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3406])\n",
      "0.34062474966049194\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1)\n",
    "print(x)\n",
    "print(x.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 线性代数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Line.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch for Deeplearning",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
