大量内容来自江大白，内容仅用于个人笔记
# 网络结构图
![2_YoloV4的网络结构](YOLOV4_Struct.jpg)
Yolov4的结构图和Yolov3相比，因为多了CSP结构，PAN结构，如果单纯看可视化流程图，会觉得很绕，不过在绘制出上面的图形后，会觉得豁然开朗，其实整体架构和Yolov3是相同的，不过使用各种新的算法思想对各个子结构都进行了改进。

先整理下Yolov4的五个基本组件：  
- **CBM**：Yolov4网络结构中的最小组件，由Conv+Bn+Mish激活函数三者组成。  
- CBL：由Conv+Bn+Leaky_relu激活函数三者组成。  
- Res unit：借鉴Resnet网络中的残差结构，让网络可以构建的更深。  
- **CSPX**：借鉴CSPNet网络结构，由三个卷积层和X个Res unint模块Concate组成。  
- **SPP**：采用1×1，5×5，9×9，13×13的最大池化的方式，进行多尺度融合。  
> mish函数  
> Mish激活函数的表达式为 Mish = x*tanh(ln(1+e^x))  
> 从图中可以看出他在负值的时候并不是完全截断  
> 而是允许比较小的负梯度流入，从而保证信息流动  
> 并且激活函数**无边界**这个特点，让他**避免了饱和**这一问题  
> 比如sigmoid，tanh激活函数通常存在梯度饱和问题，在两边极限情况下，梯度趋近于1，而Mish激活函数则巧妙的避开了这一点  
> 另外Mish函数也保证了每一点的**平滑**，从而使得梯度下降效果比Relu要好  
![Mish函数](mish函数.png)  

其他基础操作：  
Concat：张量拼接，维度会扩充，和Yolov3中的解释一样，对应于cfg文件中的route操作。
add：张量相加，不会扩充维度，对应于cfg文件中的shortcut操作。
Backbone中卷积层的数量：

和Yolov3一样，再来数一下Backbone里面的卷积层数量。

每个CSPX中包含3+2\*X个卷积层，因此整个主干网络Backbone中一共包含2+（3+2\*1）+2+（3+2\*2）+2+（3+2\*8）+2+（3+2\*8）+2+（3+2\*4）+1=72。

按照Yolov3设计的传统，这么多卷积层，主干网络不应该叫CSPDaeknet73吗？？？？

# 核心基础内容
Yolov4本质上和Yolov3相差不大，可能有些人会觉得失望。

但我觉得算法创新分为三种方式：  

第一种：面目一新的创新，比如Yolov1、Faster-RCNN、Centernet等，开创出新的算法领域，不过这种也是最难的
第二种：守正出奇的创新，比如将图像金字塔改进为特征金字塔
第三种：各种先进算法集成的创新，比如不同领域发表的最新论文的tricks，集成到自己的算法中，却发现有出乎意料的改进
Yolov4既有第二种也有第三种创新，组合尝试了大量深度学习领域最新论文的20多项研究成果，而且不得不佩服的是作者Alexey在github代码库维护的频繁程度。

目前Yolov4代码的star数量已经1万多，据我所了解，目前超过这个数量的，目标检测领域只有Facebook的Detectron(v1-v2)、和Yolo(v1-v3)官方代码库（已停止更新）。  

所以Yolov4中的各种创新方式，大白觉得还是很值得仔细研究的。

为了便于分析，将Yolov4的整体结构拆分成四大板块：
![YOLOV4_Struct_Four_Part](YOLOV4_Struct_Four_Part.jpg)
主要从以上4个部分对YoloV4的创新之处进行讲解，让大家一目了然。

- 输入端：这里指的创新主要是训练时对输入端的改进，主要包括**Mosaic数据增强**、cmBN、SAT自对抗训练  
- BackBone主干网络：将各种新的方式结合起来，包括：**CSPDarknet53**、**Mish激活函数**、Dropblock  
- Neck：目标检测网络在BackBone和最后的输出层之间往往会插入一些层，比如Yolov4中的SPP模块、FPN+PAN结构  
- Prediction：输出层的锚框机制和Yolov3相同，主要改进的是训练时的损失函数CIOU_Loss，以及预测框筛选的nms变为DIOU_nms  
  
仅对比Yolov3和Yolov4，在COCO数据集上，同样的FPS等于83左右时，Yolov4的AP是43，而Yolov3是33，直接上涨了10个百分点。  
不得不服，当然可能针对具体不同的数据集效果也不一样，但总体来说，改进效果是很优秀的，下面大白对Yolov4的各个创新点继续进行深挖。  
## 输入端创新
考虑到很多同学GPU显卡数量并不是很多，Yolov4对训练时的输入端进行改进，使得训练在单张GPU上也能有不错的成绩。比如**数据增强Mosaic、cmBN、SAT**自对抗训练。  
但感觉cmBN和SAT影响并不是很大，所以这里主要讲解Mosaic数据增强。

### Mosaic数据增强
Yolov4中使用的Mosaic是参考2019年底提出的CutMix数据增强的方式，但CutMix只使用了两张图片进行拼接，而Mosaic数据增强则采用了4张图片，随机缩放、随机裁剪、随机排布的方式进行拼接。
![Mosaic数据增强](Mosaic数据增强.jpg)
这里首先要了解**为什么要进行Mosaic数据增强呢？**

在平时项目训练时，**小目标的AP一般比中目标和大目标低很多**。而Coco数据集中也包含大量的小目标，但比较麻烦的是小目标的分布并不均匀。

首先看下小、中、大目标的定义：  
2019年发布的论文《Augmentation for small object detection》对此进行了区分：  
![小、中、大目标的定义](小、中、大目标的定义.jpg)  
可以看到小目标的定义是目标框的长宽0×0~32×32之间的物体。  
![小、中、大目标的分布](小、中、大目标的分布.jpg)  
但在整体的数据集中，小、中、大目标的占比并不均衡。
如上表所示，Coco数据集中小目标占比达到41.4%，数量比中目标和大目标都要多。  
但在所有的训练集图片中，只有52.3%的图片有小目标，而中目标和大目标的分布相对来说更加均匀一些。  
针对这种状况，Yolov4的作者采用了Mosaic数据增强的方式。  
主要有几个优点：  
- 丰富数据集：随机使用4张图片，随机缩放，再随机分布进行拼接，大大丰富了检测数据集，特别是随机缩放增加了很多小目标，让网络的鲁棒性更好。  
- 减少GPU：可能会有人说，随机缩放，普通的数据增强也可以做，但作者考虑到很多人可能只有一个GPU，因此Mosaic增强训练时，可以直接计算4张图片的数据，使得Mini-batch大小并不需要很大，一个GPU就可以达到比较好的效果。  
 
>此外，发现另一研究者的训练方式也值得借鉴，采用的数据增强和Mosaic比较类似，也是使用4张图片（不是随机分布），但训练计算loss时，采用“缺啥补啥”的思路：
如果上一个iteration中，小物体产生的loss不足（比如小于某一个阈值），则下一个iteration就用拼接图；否则就用正常图片训练，也很有意思。

### BackBone创新
#### CSPDarknet53
CSPDarknet53是在Yolov3主干网络Darknet53的基础上，借鉴2019年CSPNet的经验，产生的Backbone结构，其中包含了5个CSP模块。
![yolov4](yolov4_backbone结构.jpg)

每个CSP模块前面的卷积核的大小都是3*3，stride=2，因此可以起到**下采样**的作用。  
因为Backbone有5个CSP模块，输入图像是608*608，所以特征图变化的规律是：608->304->152->76->38->19  
经过5次CSP模块后得到19*19大小的特征图。  
而且作者只在Backbone中采用了Mish激活函数，网络后面仍然采用Leaky_relu激活函数。   
我们再看看下作者为啥要参考2019年的CSPNet，采用CSP模块？  
CSPNet论文地址：https://arxiv.org/pdf/1911.11929.pdf  
CSPNet全称是Cross Stage Paritial Network，主要从网络结构设计的角度解决推理中从计算量很大的问题。  
CSPNet的作者认为推理计算过高的问题是由于网络优化中的**梯度信息重复**导致的。  
因此采用CSP模块先将基础层的特征映射划分为两部分，然后通过跨阶段层次结构将它们合并，在**减少了计算量**的同时可以保证准确率。  
因此Yolov4在主干网络Backbone采用CSPDarknet53网络结构，主要有三个方面的优点：  
- 优点一：增强CNN的学习能力，使得在轻量化的同时保持准确性。  
- 优点二：降低计算瓶颈  
- 优点三：降低内存成本  

### Neck创新
在目标检测领域，为了更好的提取融合特征，通常在Backbone和输出层，会插入一些层，这个部分称为Neck。相当于目标检测网络的颈部，也是非常关键的。
Yolov4的Neck结构主要采用了SPP模块、FPN+PAN的方式。

#### （1）SPP模块
SPP模块，其实在Yolov3中已经存在了，在Yolov4的C++代码文件夹中有一个Yolov3_spp版本，但有的同学估计从来没有使用过，在Yolov4中，SPP模块仍然是在Backbone主干网络之后：  

作者在SPP模块中，使用k={1×1,5×5,9×9,13×13}的最大池化的方式，再将不同尺度的特征图进行Concat操作。  
注意：这里最大池化采用padding操作，移动的步长为1，比如13×13的输入特征图，使用5×5大小的池化核池化，padding=2，因此池化后的特征图仍然是13×13大小。  
#### （2）FPN+PAN
PAN结构比较有意思，看了网上Yolov4关于这个部分的讲解，大多都是讲的比较笼统的，而PAN是借鉴**2018年图像分割领域PANet的创新点，有些同学可能不是很清楚。  
下面大白将这个部分拆解开来，看下Yolov3和Yolov4**中是如何设计的。  

Yolov3各个网络结构  
![Yolov4各个网络结构](Yolov4各个网络结构.png)  
可以看到经过几次下采样，三个紫色箭头指向的地方，输出分别是**76×76、38×38、19×19**。  
以及最后的Prediction中用于预测的三个特征图①19×19×255、②38×38×255、③76×76×255 [注：255表示80类别 (1+4+80)×3=255]。  
我们将Neck部分用立体图画出来，更直观的看下两部分之间是如何通过FPN结构融合的。  


如图所示，FPN是自顶向下的，将高层的特征信息通过上采样的方式进行传递融合，得到进行预测的特征图。

Yolov4各个网络结构
而Yolov4中Neck这部分除了使用FPN外，还在此基础上使用了PAN结构。


前面CSPDarknet53中讲到，每个CSP模块前面的卷积核都是3×3大小，相当于下采样操作。
因此可以看到三个紫色箭头处的特征图是76×76、38×38、19×19。
以及最后Prediction中用于预测的三个特征图：①76×76×255，②38×38×255，③19×19×255。
我们也看下Neck部分的立体图像，看下两部分是如何通过FPN+PAN结构进行融合的。

和Yolov3的FPN层不同，Yolov4在FPN层的后面还添加了一个自底向上的特征金字塔。
其中包含两个PAN结构。
这样结合操作，FPN层自顶向下传达强语义特征，而特征金字塔则自底向上传达强定位特征，两两联手，从不同的主干层对不同的检测层进行特征聚合,这样的操作确实很皮。
FPN+PAN借鉴的是18年CVPR的PANet，当时主要应用于图像分割领域，但Alexey将其拆分应用到Yolov4中，进一步提高特征提取的能力。

不过这里需要注意几点：
注意一：
Yolov3的FPN层输出的三个大小不一的特征图①②③直接进行预测
但Yolov4的FPN层，只使用最后的一个76×76特征图①，而经过两次PAN结构，输出预测的特征图②和③。
这里的不同也体现在cfg文件中，这一点有很多同学之前不太明白。
比如Yolov3.cfg中输入时608×608，最后的三个Yolo层中，
第一个Yolo层是最小的特征图19×19，mask=6,7,8，对应最大的anchor box。
第二个Yolo层是中等的特征图38×38，mask=3,4,5，对应中等的anchor box。
第三个Yolo层是最大的特征图76×76，mask=0,1,2，对应最小的anchor box。
而Yolov4.cfg则恰恰相反
第一个Yolo层是最大的特征图76×76，mask=0,1,2，对应最小的anchor box。
第二个Yolo层是中等的特征图38×38，mask=3,4,5，对应中等的anchor box。
第三个Yolo层是最小的特征图19×19，mask=6,7,8，对应最大的anchor box。
注意二：
原本的PANet网络的PAN结构中，两个特征图结合是采用shortcut操作，而Yolov4中则采用concat（route）操作，特征图融合后的尺寸发生了变化。

这里也可以对应Yolov4的netron网络图查看，很有意思。



在2019年的《DC-SPP-Yolo》文章：https://arxiv.org/ftp/arxiv/papers/1903/1903.08589.pdf
也对Yolo目标检测的SPP模块进行了对比测试。
和Yolov4作者的研究相同，采用SPP模块的方式，比单纯的使用k×k最大池化的方式，更有效的增加主干特征的接收范围，显著的分离了最重要的上下文特征。
Yolov4的作者在使用608×608大小的图像进行测试时发现，在COCO目标检测任务中，以0.5%的额外计算代价将AP50增加了2.7%，因此Yolov4中也采用了SPP模块。
## yolov4的网络结构图
![yolov4网络结构图](yolov4网络结构图.png)