{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们以一个简单的房屋价格预测作为例子来解释线性回归的基本要素。这个应用的目标是预测一栋房子的售出价格（元）。我们知道这个价格取决于很多因素，即面积（平方米）和房龄（年）。接下来我们希望探索价格与这两个因素的具体关系。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "设房屋的面积为x1，房龄为x2，售出价格为y。我们需要建立基于输入x1和x2来计算输出y的表达式，也就是模型。顾名思义，线性回归假设输出与各个输入之间是线性关系：\n",
    "y = x1w1 + x2w2 +b\n",
    "其中w1和w2是权重，b是偏差，且均为标量。它们是线性回归模型的参数。模型输出y是线性回归对真实价格y的预测或估计。我们通常允许它们之间有一点误差。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来我们需要通过数据来寻找特定的模型参数值，使模型在数据上的误差尽可能小。这个过程叫做模型训练。下面我们介绍模型训练所涉及的3个要素。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 训练数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们通常收集一系列的真实数据，例如多栋房屋的真实售出价格和它们对应的面积和房龄。我们希望在这个数据上面寻找模型参数来是模型的预测价格与真实价格的误差最小。在机器学习术语里，该数据集被称为训练数据集或训练集，一栋房屋被称为一个样本，其真实售出价格叫做标签，用来预测标签的两个因素叫做特征。特征用来表征样本的特点。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假设我们采集的样本数为n，索引为i的样本的特征为x1和x2，标签为y。对于索引为i的房屋，线性回归模型的房屋价格预测表达式为："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y=x1w1+x2w2+b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 损失函数\n",
    "在模型训练中，我们需要衡量价格预测值与真实值之间的误差。通常我们会选取一个非负数作为误差，且数值越小表示误差越小。一个常用的选择是平方函数。它在评估索引为i的样本误差的表达式为： l(w1,w2,b)= 1/2 * (y-y)2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中常数1/2使对平方项求导后的常数系数为1，这样在形式上稍微简单一些。显然，误差越小表示预测价格与真实价格越想尽，且当二者相等时误差为0。给定训练数据集，这个误差只与模型参数相关，因此我们将它记为以模型参数为参数的函数。在机器学习力，将衡量误差的函数称为损失函数（loss function）。这里使用的平方误差函数也称为平方损失。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通常，我们用训练数据集中所有样本误差的平均来衡量模型预测的质量，即："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![loss](Loss.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在模型训练中，我们希望找出一组模型参数，记为w1\\*,w2\\*,b\\*，来使训练样本平均损失最小："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "w1\\*,w2\\*,b\\*=arg minl(w1,w2,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 优化算法\n",
    "当模型和损失函数形式较为简单时，上面的误差最小化问题的解可以用公式直接表达出来。这类解叫做解析解。本节使用的线性回归和平方误差刚好属于这个范畴。然而，大多数深度学习模型并没有解析解，只能通过优化算法有限次迭代模型参数来尽可能降低损失函数的值。这类解叫做数值解。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在求数值解的优化算法中，小批量随机梯度下降在深度学习中被广泛使用。他的算法很简单：先选取一组模型参数的初始值，如随机选取；接下来对参数进行多次迭代，使每次迭代都可能降低损失函数的值。在每次迭代中，先随机均匀采样一个由固定数目训练数据样本所组成的小批量（mini-batch），然后求小批量中数据样本的平均损失有关模型参参数的导数（梯度），最后用此结果与预先设定的一个整数的乘积作为作为模型参数在本次迭代的减小量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在训练本节讨论的线性回归模型的过程中，模型的每个参数将作如下迭代："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![mini-batch-Loss](mini-batch-Loss.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在上式中，B代表每个小批量中的样本个数，n称作学习率并取正数。需要抢到的是，**这里的批量大小和学习率的值是认为设定的，并不是通过模型训练学出的，因此叫做超参数。**我们通常所说的“调参”指的正是调节超参数，例如通过反复试错来找到超参数合适的值。在少数情况下，超参数也可以通过模型训练学出。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![模型预测-文字-character](模型预测-文字-character.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 小结\n",
    "- 和大多数深度学习模型一样，对于线性回归这样一种单层神经网络，它的基本要素包括模型、讯联数据、损失函数和优化算法。\n",
    "- 既可以用神经网络图表示线性回归，又可以用矢量计算表示该模型\n",
    "- 应该尽可能采用矢量计算，以提升计算效率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch for Deeplearning",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
